{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "ImageGeneratorDCGAN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "267d5504009eca2b809a2691131366baebe98436",
        "id": "B8nRWthodt0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import datetime\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import savetxt\n",
        "import pandas as pd\n",
        "import sys\n",
        "%matplotlib inline\n",
        "array_sum = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvUj_IxLeZSO",
        "colab_type": "code",
        "outputId": "8884410f-129a-4890-9069-b4db5085d65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fc376df46433261bfeb643a95793718a9d969ed1",
        "id": "nXVubwxBdt0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(z, output_channel_dim, training):\n",
        "    with tf.variable_scope(\"generator\", reuse= not training):\n",
        "        \n",
        "        # 8x8x1024\n",
        "        fully_connected = tf.layers.dense(z, 8*8*1024)\n",
        "        fully_connected = tf.reshape(fully_connected, (-1, 8, 8, 1024))\n",
        "        fully_connected = tf.nn.leaky_relu(fully_connected)\n",
        "\n",
        "        # 8x8x1024 -> 16x16x512\n",
        "        trans_conv1 = tf.layers.conv2d_transpose(inputs=fully_connected,\n",
        "                                                 filters=512,\n",
        "                                                 kernel_size=[5,5],\n",
        "                                                 strides=[2,2],\n",
        "                                                 padding=\"SAME\",\n",
        "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                                 name=\"trans_conv1\")\n",
        "        batch_trans_conv1 = tf.layers.batch_normalization(inputs = trans_conv1,\n",
        "                                                          training=training,\n",
        "                                                          epsilon=EPSILON,\n",
        "                                                          name=\"batch_trans_conv1\")\n",
        "        trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1,\n",
        "                                           name=\"trans_conv1_out\")\n",
        "        \n",
        "        # 16x16x512 -> 32x32x256\n",
        "        trans_conv2 = tf.layers.conv2d_transpose(inputs=trans_conv1_out,\n",
        "                                                 filters=256,\n",
        "                                                 kernel_size=[5,5],\n",
        "                                                 strides=[2,2],\n",
        "                                                 padding=\"SAME\",\n",
        "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                                 name=\"trans_conv2\")\n",
        "        batch_trans_conv2 = tf.layers.batch_normalization(inputs = trans_conv2,\n",
        "                                                          training=training,\n",
        "                                                          epsilon=EPSILON,\n",
        "                                                          name=\"batch_trans_conv2\")\n",
        "        trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2,\n",
        "                                           name=\"trans_conv2_out\")\n",
        "        \n",
        "        # 32x32x256 -> 64x64x128\n",
        "        trans_conv3 = tf.layers.conv2d_transpose(inputs=trans_conv2_out,\n",
        "                                                 filters=128,\n",
        "                                                 kernel_size=[5,5],\n",
        "                                                 strides=[2,2],\n",
        "                                                 padding=\"SAME\",\n",
        "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                                 name=\"trans_conv3\")\n",
        "        batch_trans_conv3 = tf.layers.batch_normalization(inputs = trans_conv3,\n",
        "                                                          training=training,\n",
        "                                                          epsilon=EPSILON,\n",
        "                                                          name=\"batch_trans_conv3\")\n",
        "        trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3,\n",
        "                                           name=\"trans_conv3_out\")\n",
        "        \n",
        "        # 64x64x128 -> 128x128x64\n",
        "        trans_conv4 = tf.layers.conv2d_transpose(inputs=trans_conv3_out,\n",
        "                                                 filters=64,\n",
        "                                                 kernel_size=[5,5],\n",
        "                                                 strides=[2,2],\n",
        "                                                 padding=\"SAME\",\n",
        "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                                 name=\"trans_conv4\")\n",
        "        batch_trans_conv4 = tf.layers.batch_normalization(inputs = trans_conv4,\n",
        "                                                          training=training,\n",
        "                                                          epsilon=EPSILON,\n",
        "                                                          name=\"batch_trans_conv4\")\n",
        "        trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4,\n",
        "                                           name=\"trans_conv4_out\")\n",
        "        \n",
        "        # 128x128x64 -> 128x128x3\n",
        "        logits = tf.layers.conv2d_transpose(inputs=trans_conv4_out,\n",
        "                                            filters=3,\n",
        "                                            kernel_size=[5,5],\n",
        "                                            strides=[1,1],\n",
        "                                            padding=\"SAME\",\n",
        "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                            name=\"logits\")\n",
        "        out = tf.tanh(logits, name=\"out\")\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ba53a4bb09dbcd57d3e3392f74ccd054ecf23ecb",
        "id": "SSIfMkOEdt0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator(x, reuse):\n",
        "    with tf.variable_scope(\"discriminator\", reuse=reuse): \n",
        "        \n",
        "        # 128*128*3 -> 64x64x64 \n",
        "        conv1 = tf.layers.conv2d(inputs=x,\n",
        "                                 filters=64,\n",
        "                                 kernel_size=[5,5],\n",
        "                                 strides=[2,2],\n",
        "                                 padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                 name='conv1')\n",
        "        batch_norm1 = tf.layers.batch_normalization(conv1,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm1')\n",
        "        conv1_out = tf.nn.leaky_relu(batch_norm1,\n",
        "                                     name=\"conv1_out\")\n",
        "        \n",
        "        # 64x64x64-> 32x32x128 \n",
        "        conv2 = tf.layers.conv2d(inputs=conv1_out,\n",
        "                                 filters=128,\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 strides=[2, 2],\n",
        "                                 padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                 name='conv2')\n",
        "        batch_norm2 = tf.layers.batch_normalization(conv2,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm2')\n",
        "        conv2_out = tf.nn.leaky_relu(batch_norm2,\n",
        "                                     name=\"conv2_out\")\n",
        "        \n",
        "        # 32x32x128 -> 16x16x256  \n",
        "        conv3 = tf.layers.conv2d(inputs=conv2_out,\n",
        "                                 filters=256,\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 strides=[2, 2],\n",
        "                                 padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                 name='conv3')\n",
        "        batch_norm3 = tf.layers.batch_normalization(conv3,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm3')\n",
        "        conv3_out = tf.nn.leaky_relu(batch_norm3,\n",
        "                                     name=\"conv3_out\")\n",
        "        \n",
        "        # 16x16x256 -> 16x16x512\n",
        "        conv4 = tf.layers.conv2d(inputs=conv3_out,\n",
        "                                 filters=512,\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 strides=[1, 1],\n",
        "                                 padding=\"SAME\",\n",
        "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                 name='conv4')\n",
        "        batch_norm4 = tf.layers.batch_normalization(conv4,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm4')\n",
        "        conv4_out = tf.nn.leaky_relu(batch_norm4,\n",
        "                                     name=\"conv4_out\")\n",
        "        \n",
        "        # 16x16x512 -> 8x8x1024\n",
        "        conv5 = tf.layers.conv2d(inputs=conv4_out,\n",
        "                                filters=1024,\n",
        "                                kernel_size=[5, 5],\n",
        "                                strides=[2, 2],\n",
        "                                padding=\"SAME\",\n",
        "                                kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
        "                                name='conv5')\n",
        "        batch_norm5 = tf.layers.batch_normalization(conv5,\n",
        "                                                    training=True,\n",
        "                                                    epsilon=EPSILON,\n",
        "                                                    name='batch_norm5')\n",
        "        conv5_out = tf.nn.leaky_relu(batch_norm5,\n",
        "                                     name=\"conv5_out\")\n",
        "\n",
        "        flatten = tf.reshape(conv5_out, (-1, 8*8*1024))\n",
        "        logits = tf.layers.dense(inputs=flatten,\n",
        "                                 units=1,\n",
        "                                 activation=None)\n",
        "        out = tf.sigmoid(logits)\n",
        "        return out, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8ef5bbb8e4d157577f1b15600aa64cb40289a754",
        "id": "zAB6e5Zcdt0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_loss(input_real, input_z, output_channel_dim):\n",
        "    g_model = generator(input_z, output_channel_dim, True)\n",
        "\n",
        "    noisy_input_real = input_real + tf.random_normal(shape=tf.shape(input_real),\n",
        "                                                     mean=0.0,\n",
        "                                                     stddev=random.uniform(0.0, 0.1),\n",
        "                                                     dtype=tf.float32)\n",
        "    \n",
        "    d_model_real, d_logits_real = discriminator(noisy_input_real, reuse=False)\n",
        "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
        "    \n",
        "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
        "                                                                         labels=tf.ones_like(d_model_real)*random.uniform(0.9, 1.0)))\n",
        "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
        "                                                                         labels=tf.zeros_like(d_model_fake)))\n",
        "    d_loss = tf.reduce_mean(0.5 * (d_loss_real + d_loss_fake))\n",
        "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
        "                                                                    labels=tf.ones_like(d_model_fake)))\n",
        "    return d_loss, g_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "01820b197de1b6d0ca39592043308557d941937a",
        "id": "R__LaaVKdt0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_optimizers(d_loss, g_loss):\n",
        "    t_vars = tf.trainable_variables()\n",
        "    g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
        "    d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
        "    \n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    gen_updates = [op for op in update_ops if op.name.startswith('generator')]\n",
        "    \n",
        "    with tf.control_dependencies(gen_updates):\n",
        "        d_train_opt = tf.train.AdamOptimizer(learning_rate=LR_D, beta1=BETA1).minimize(d_loss, var_list=d_vars)\n",
        "        g_train_opt = tf.train.AdamOptimizer(learning_rate=LR_G, beta1=BETA1).minimize(g_loss, var_list=g_vars)  \n",
        "    return d_train_opt, g_train_opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BKiT1vDdt0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_inputs(real_dim, z_dim):\n",
        "    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='inputs_real')\n",
        "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name=\"input_z\")\n",
        "    learning_rate_G = tf.placeholder(tf.float32, name=\"lr_g\")\n",
        "    learning_rate_D = tf.placeholder(tf.float32, name=\"lr_d\")\n",
        "    return inputs_real, inputs_z, learning_rate_G, learning_rate_D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3a7808bacf25966ab5a8ca06e2e1075ac8eeb662",
        "id": "RwmTdg0hdt0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_samples(sample_images, name, epoch):\n",
        "    figure, axes = plt.subplots(1, len(sample_images), figsize = (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    for index, axis in enumerate(axes):\n",
        "        axis.axis('off')\n",
        "        #flatten() change 3d array into 1d\n",
        "        image_array = sample_images[index].flatten()\n",
        "        if epoch == 50:\n",
        "          !kill -9 -1\n",
        "          array_sum = np.concatenate((image_array, array_sum), axis=0)\n",
        "        else:\n",
        "          print(epoch)\n",
        "          print(image_array.size)\n",
        "          print(image_array.shape)\n",
        "          print(image_array)\n",
        "    if epoch == 300:\n",
        "    \t#save to csv file \n",
        "      #pd.DataFrame(image_array).to_csv(\"/content/drive/My Drive/Colab Notebooks/image_generator/output.csv\")\n",
        "      savetxt('/content/drive/My Drive/Colab Notebooks/image_generator/output.csv', array_sum, delimiter=' ')\n",
        "      #print(array_sum.size)\n",
        "      #print(array_sum.shape)\n",
        "      #print(array_sum)\n",
        "        #axis.imshow(image_array)\n",
        "        #实现array到image的转换\n",
        "        #image = Image.fromarray(image_array)\n",
        "        #image.save(name+\"_\"+str(epoch)+\"_\"+str(index)+\".png\") \n",
        "    #plt.savefig(name+\"_\"+str(epoch)+\".png\", bbox_inches='tight', pad_inches=0)\n",
        "    #plt.show()\n",
        "    #plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXLGmyBUdt0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(sess, input_z, out_channel_dim, epoch):\n",
        "    example_z = np.random.uniform(-1, 1, size=[SAMPLES_TO_SHOW, input_z.get_shape().as_list()[-1]])\n",
        "    samples = sess.run(generator(input_z, out_channel_dim, False), feed_dict={input_z: example_z})\n",
        "    samples = samples.flatten()\n",
        "    \n",
        "    if epoch == 300:\n",
        "      print(\"samples:\", samples)\n",
        "      print(\"samples_size:\", samples.size)\n",
        "      savetxt('/content/drive/output.csv')\n",
        "    else:\n",
        "        print(\"epoch:\", epoch)\n",
        "    #sample_images = [((sample + 1.0) * 127.5).astype(np.uint8) for sample in samples] #int8 字节（-128 ~ 127）\n",
        "    #show_samples(sample_images, OUTPUT_DIR + \"samples\", epoch)      ======================already 127 \n",
        "    #print(\"sample_images:\", sample_images)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0ed8f1c378f936ac81ae89b35d5b6914cd6efbbb",
        "id": "7ecFv9S9dt01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summarize_epoch(epoch, duration, sess, d_losses, g_losses, input_z, data_shape):\n",
        "    minibatch_size = int(data_shape[0]//BATCH_SIZE)\n",
        "    # print(\"Epoch {}/{}\".format(epoch, EPOCHS),\n",
        "    #        \"\\nDuration: {:.5f}\".format(duration),\n",
        "    #        \"\\nD Loss: {:.5f}\".format(np.mean(d_losses[-minibatch_size:])),\n",
        "    #        \"\\nG Loss: {:.5f}\".format(np.mean(g_losses[-minibatch_size:])))\n",
        "    # fig, ax = plt.subplots()\n",
        "    # plt.plot(d_losses, label='Discriminator', alpha=0.6)\n",
        "    # plt.plot(g_losses, label='Generator', alpha=0.6)\n",
        "    # plt.title(\"Losses\")\n",
        "    # plt.legend()\n",
        "    # plt.savefig(OUTPUT_DIR + \"losses_\" + str(epoch) + \".png\")\n",
        "    # plt.show()\n",
        "    # plt.close()\n",
        "    #print(input_z)\n",
        "    #print(\"sess\", sess, \"d_losses:\", d_losses, \"input_z:\", input_z)\n",
        "    test(sess, input_z, data_shape[3], epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FIugUZqdt05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(data):\n",
        "    batches = []\n",
        "    for i in range(int(data.shape[0]//BATCH_SIZE)):\n",
        "        batch = data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
        "        augmented_images = []\n",
        "        for img in batch:\n",
        "            image = Image.fromarray(img)\n",
        "            if random.choice([True, False]):\n",
        "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            augmented_images.append(np.asarray(image))\n",
        "        batch = np.asarray(augmented_images)\n",
        "        normalized_batch = (batch / 127.5) - 1.0\n",
        "        batches.append(normalized_batch)\n",
        "    return batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1emVMLFdt09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(get_batches, data_shape, checkpoint_to_load=None):\n",
        "    #print(\"data_shape:\", data_shape)\n",
        "    input_images, input_z, lr_G, lr_D = model_inputs(data_shape[1:], NOISE_SIZE)\n",
        "    #print(\"input_images\", input_images, \"input_z\", input_z)\n",
        "    d_loss, g_loss = model_loss(input_images, input_z, data_shape[3])\n",
        "    d_opt, g_opt = model_optimizers(d_loss, g_loss)\n",
        "    #print(\"d_opt:\", d_opt, \"g_opt:\", g_opt)\n",
        "    #print(\"get_batches:\", get_batches)\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        epoch = 0\n",
        "        iteration = 0\n",
        "        d_losses = []\n",
        "        g_losses = []\n",
        "        \n",
        "        for epoch in range(EPOCHS):        \n",
        "            epoch += 1\n",
        "            start_time = time.time()\n",
        "\n",
        "            for batch_images in get_batches:\n",
        "                iteration += 1\n",
        "                batch_z = np.random.uniform(-1, 1, size=(BATCH_SIZE, NOISE_SIZE))\n",
        "                _ = sess.run(d_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_D: LR_D})\n",
        "                _ = sess.run(g_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_G: LR_G})\n",
        "                d_losses.append(d_loss.eval({input_z: batch_z, input_images: batch_images}))\n",
        "                g_losses.append(g_loss.eval({input_z: batch_z}))\n",
        "\n",
        "            summarize_epoch(epoch, time.time()-start_time, sess, d_losses, g_losses, input_z, data_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d857345ed6c3ba7e4f614fa90b5ca42adb9917cf",
        "id": "haT4YG4_dt1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paths\n",
        "INPUT_DATA_DIR = \"/content/drive/My Drive/Colab Notebooks/image_generator/\" # Path to the folder with input images. For more info check simspons_dataset.txt\n",
        "OUTPUT_DIR = './{date:%Y-%m-%d_%H:%M:%S}/'.format(date=datetime.datetime.now())\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JtZdl_adt1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "IMAGE_SIZE = 128\n",
        "NOISE_SIZE = 100\n",
        "LR_D = 0.00004\n",
        "LR_G = 0.0004\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 300\n",
        "BETA1 = 0.5\n",
        "WEIGHT_INIT_STDDEV = 0.02\n",
        "EPSILON = 0.00005\n",
        "SAMPLES_TO_SHOW = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GCmrEE3e2T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readcsv(filename):\n",
        "  data = pd.read_csv(filename) #Please add four spaces here before this line\n",
        "  return(np.array(data)) #Please add four spaces here before this line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1ee6349afccb4d2f29f36d6605dd2f156350821a",
        "scrolled": false,
        "id": "wjcKFrFYdt1K",
        "colab_type": "code",
        "outputId": "7214f572-d274-49bc-95b2-c8c1900648bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "#input_images = np.asarray([np.asarray(Image.open(\"/content/drive/My Drive/Colab Notebooks/AI_Lab/image_generator/1.png\").resize((IMAGE_SIZE, IMAGE_SIZE))) for file in glob(INPUT_DATA_DIR + '*')])\n",
        "\n",
        "#print (input_images.shape)\n",
        "#print (input_images.size) #294912\n",
        "#!kill -9 -1\n",
        "#np.random.shuffle(input_images)\n",
        "#print (\"==========================\")\n",
        "#sample_images = random.sample(list(input_images), SAMPLES_TO_SHOW)\n",
        "#sample_images = list(input_images)\n",
        "#print(sample_images)\n",
        "Input_data = readcsv(\"/content/drive/My Drive/Colab Notebooks/image_generator/data02.csv\")   #data02 295098   data02(295098)-186=293912 这里data02已经减去了这么多，为了方便reshape矩阵\n",
        "#Input_data = np.reshape(Input_data, (128, 3)) #这里还是要用它原来的维度 (6, 128, 128, 3)\n",
        "#Input_data = np.reshape(Input_data, (128, 128, 3))\n",
        "Input_data = np.reshape(Input_data, (294912,))\n",
        "#print(Input_data.size)\n",
        "#print(Input_data.shape)\n",
        "#print(Input_data)\n",
        "Input_data = np.reshape(Input_data, (6, 128, 128, 3))\n",
        "#print(Input_data.size)\n",
        "#Input_data = np.transpose(Input_data)\n",
        "#print(Input_data)\n",
        "#print (Input_data.shape)\n",
        "#print (Input_data.size)\n",
        "#!kill -9 -1\n",
        "#show_samples(Input_data, OUTPUT_DIR + \"inputs\", 0)\n",
        "with tf.Graph().as_default():\n",
        "    train(get_batches(Input_data), Input_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-6a171d8d9e59>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-21-6a171d8d9e59>:16: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "WARNING:tensorflow:From <ipython-input-21-6a171d8d9e59>:20: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From <ipython-input-22-5b9e48b97d85>:11: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "epoch: 1\n",
            "epoch: 2\n",
            "epoch: 3\n",
            "epoch: 4\n",
            "epoch: 5\n",
            "epoch: 6\n",
            "epoch: 7\n",
            "epoch: 8\n",
            "epoch: 9\n",
            "epoch: 10\n",
            "epoch: 11\n",
            "epoch: 12\n",
            "epoch: 13\n",
            "epoch: 14\n",
            "epoch: 15\n",
            "epoch: 16\n",
            "epoch: 17\n",
            "epoch: 18\n",
            "epoch: 19\n",
            "epoch: 20\n",
            "epoch: 21\n",
            "epoch: 22\n",
            "epoch: 23\n",
            "epoch: 24\n",
            "epoch: 25\n",
            "epoch: 26\n",
            "epoch: 27\n",
            "epoch: 28\n",
            "epoch: 29\n",
            "epoch: 30\n",
            "epoch: 31\n",
            "epoch: 32\n",
            "epoch: 33\n",
            "epoch: 34\n",
            "epoch: 35\n",
            "epoch: 36\n",
            "epoch: 37\n",
            "epoch: 38\n",
            "epoch: 39\n",
            "epoch: 40\n",
            "epoch: 41\n",
            "epoch: 42\n",
            "epoch: 43\n",
            "epoch: 44\n",
            "epoch: 45\n",
            "epoch: 46\n",
            "epoch: 47\n",
            "epoch: 48\n",
            "epoch: 49\n",
            "epoch: 50\n",
            "epoch: 51\n",
            "epoch: 52\n",
            "epoch: 53\n",
            "epoch: 54\n",
            "epoch: 55\n",
            "epoch: 56\n",
            "epoch: 57\n",
            "epoch: 58\n",
            "epoch: 59\n",
            "epoch: 60\n",
            "epoch: 61\n",
            "epoch: 62\n",
            "epoch: 63\n",
            "epoch: 64\n",
            "epoch: 65\n",
            "epoch: 66\n",
            "epoch: 67\n",
            "epoch: 68\n",
            "epoch: 69\n",
            "epoch: 70\n",
            "epoch: 71\n",
            "epoch: 72\n",
            "epoch: 73\n",
            "epoch: 74\n",
            "epoch: 75\n",
            "epoch: 76\n",
            "epoch: 77\n",
            "epoch: 78\n",
            "epoch: 79\n",
            "epoch: 80\n",
            "epoch: 81\n",
            "epoch: 82\n",
            "epoch: 83\n",
            "epoch: 84\n",
            "epoch: 85\n",
            "epoch: 86\n",
            "epoch: 87\n",
            "epoch: 88\n",
            "epoch: 89\n",
            "epoch: 90\n",
            "epoch: 91\n",
            "epoch: 92\n",
            "epoch: 93\n",
            "epoch: 94\n",
            "epoch: 95\n",
            "epoch: 96\n",
            "epoch: 97\n",
            "epoch: 98\n",
            "epoch: 99\n",
            "epoch: 100\n",
            "epoch: 101\n",
            "epoch: 102\n",
            "epoch: 103\n",
            "epoch: 104\n",
            "epoch: 105\n",
            "epoch: 106\n",
            "epoch: 107\n",
            "epoch: 108\n",
            "epoch: 109\n",
            "epoch: 110\n",
            "epoch: 111\n",
            "epoch: 112\n",
            "epoch: 113\n",
            "epoch: 114\n",
            "epoch: 115\n",
            "epoch: 116\n",
            "epoch: 117\n",
            "epoch: 118\n",
            "epoch: 119\n",
            "epoch: 120\n",
            "epoch: 121\n",
            "epoch: 122\n",
            "epoch: 123\n",
            "epoch: 124\n",
            "epoch: 125\n",
            "epoch: 126\n",
            "epoch: 127\n",
            "epoch: 128\n",
            "epoch: 129\n",
            "epoch: 130\n",
            "epoch: 131\n",
            "epoch: 132\n",
            "epoch: 133\n",
            "epoch: 134\n",
            "epoch: 135\n",
            "epoch: 136\n",
            "epoch: 137\n",
            "epoch: 138\n",
            "epoch: 139\n",
            "epoch: 140\n",
            "epoch: 141\n",
            "epoch: 142\n",
            "epoch: 143\n",
            "epoch: 144\n",
            "epoch: 145\n",
            "epoch: 146\n",
            "epoch: 147\n",
            "epoch: 148\n",
            "epoch: 149\n",
            "epoch: 150\n",
            "epoch: 151\n",
            "epoch: 152\n",
            "epoch: 153\n",
            "epoch: 154\n",
            "epoch: 155\n",
            "epoch: 156\n",
            "epoch: 157\n",
            "epoch: 158\n",
            "epoch: 159\n",
            "epoch: 160\n",
            "epoch: 161\n",
            "epoch: 162\n",
            "epoch: 163\n",
            "epoch: 164\n",
            "epoch: 165\n",
            "epoch: 166\n",
            "epoch: 167\n",
            "epoch: 168\n",
            "epoch: 169\n",
            "epoch: 170\n",
            "epoch: 171\n",
            "epoch: 172\n",
            "epoch: 173\n",
            "epoch: 174\n",
            "epoch: 175\n",
            "epoch: 176\n",
            "epoch: 177\n",
            "epoch: 178\n",
            "epoch: 179\n",
            "epoch: 180\n",
            "epoch: 181\n",
            "epoch: 182\n",
            "epoch: 183\n",
            "epoch: 184\n",
            "epoch: 185\n",
            "epoch: 186\n",
            "epoch: 187\n",
            "epoch: 188\n",
            "epoch: 189\n",
            "epoch: 190\n",
            "epoch: 191\n",
            "epoch: 192\n",
            "epoch: 193\n",
            "epoch: 194\n",
            "epoch: 195\n",
            "epoch: 196\n",
            "epoch: 197\n",
            "epoch: 198\n",
            "epoch: 199\n",
            "epoch: 200\n",
            "epoch: 201\n",
            "epoch: 202\n",
            "epoch: 203\n",
            "epoch: 204\n",
            "epoch: 205\n",
            "epoch: 206\n",
            "epoch: 207\n",
            "epoch: 208\n",
            "epoch: 209\n",
            "epoch: 210\n",
            "epoch: 211\n",
            "epoch: 212\n",
            "epoch: 213\n",
            "epoch: 214\n",
            "epoch: 215\n",
            "epoch: 216\n",
            "epoch: 217\n",
            "epoch: 218\n",
            "epoch: 219\n",
            "epoch: 220\n",
            "epoch: 221\n",
            "epoch: 222\n",
            "epoch: 223\n",
            "epoch: 224\n",
            "epoch: 225\n",
            "epoch: 226\n",
            "epoch: 227\n",
            "epoch: 228\n",
            "epoch: 229\n",
            "epoch: 230\n",
            "epoch: 231\n",
            "epoch: 232\n",
            "epoch: 233\n",
            "epoch: 234\n",
            "epoch: 235\n",
            "epoch: 236\n",
            "epoch: 237\n",
            "epoch: 238\n",
            "epoch: 239\n",
            "epoch: 240\n",
            "epoch: 241\n",
            "epoch: 242\n",
            "epoch: 243\n",
            "epoch: 244\n",
            "epoch: 245\n",
            "epoch: 246\n",
            "epoch: 247\n",
            "epoch: 248\n",
            "epoch: 249\n",
            "epoch: 250\n",
            "epoch: 251\n",
            "epoch: 252\n",
            "epoch: 253\n",
            "epoch: 254\n",
            "epoch: 255\n",
            "epoch: 256\n",
            "epoch: 257\n",
            "epoch: 258\n",
            "epoch: 259\n",
            "epoch: 260\n",
            "epoch: 261\n",
            "epoch: 262\n",
            "epoch: 263\n",
            "epoch: 264\n",
            "epoch: 265\n",
            "epoch: 266\n",
            "epoch: 267\n",
            "epoch: 268\n",
            "epoch: 269\n",
            "epoch: 270\n",
            "epoch: 271\n",
            "epoch: 272\n",
            "epoch: 273\n",
            "epoch: 274\n",
            "epoch: 275\n",
            "epoch: 276\n",
            "epoch: 277\n",
            "epoch: 278\n",
            "epoch: 279\n",
            "epoch: 280\n",
            "epoch: 281\n",
            "epoch: 282\n",
            "epoch: 283\n",
            "epoch: 284\n",
            "epoch: 285\n",
            "epoch: 286\n",
            "epoch: 287\n",
            "epoch: 288\n",
            "epoch: 289\n",
            "epoch: 290\n",
            "epoch: 291\n",
            "epoch: 292\n",
            "epoch: 293\n",
            "epoch: 294\n",
            "epoch: 295\n",
            "epoch: 296\n",
            "epoch: 297\n",
            "epoch: 298\n",
            "epoch: 299\n",
            "samples: [ 1.5561574e-04 -9.4264913e-05 -4.4462653e-05 ... -8.3645625e-04\n",
            " -1.2022897e-04 -8.4746501e-04]\n",
            "samples_size: 245760\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}